{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42133ebe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 4 Demo: Updated Hybrid Explanation System\n",
    "================================================\n",
    "Compatible with UNSW-NB15 dataset and latest Step 1-3 implementations\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Step 4 Demo: Hybrid Explanations - UNSW-NB15 Dataset\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: Configuration (Updated for UNSW-NB15)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[1/8] Loading Configuration...\")\n",
    "\n",
    "# File paths\n",
    "LSTM_MODEL = '../step1_lstm_xai/best_lstm.pt'\n",
    "SCALER = '../step1_lstm_xai/scaler.joblib'\n",
    "CAUSAL_GRAPH = '../step2_causal_discovery/causal_graph.gpickle'\n",
    "DATA_FILE = '../UNSW_NB15_training-set.csv'\n",
    "\n",
    "# UNSW-NB15 Feature names (42 features after dropping id, attack_cat)\n",
    "FEATURE_NAMES = [\n",
    "    'dur', 'proto', 'service', 'state', 'spkts', 'dpkts',\n",
    "    'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload',\n",
    "    'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit',\n",
    "    'swin', 'stcpb', 'dtcpb', 'dwin', 'tcprtt', 'synack', 'ackdat',\n",
    "    'smean', 'dmean', 'trans_depth', 'response_body_len',\n",
    "    'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm',\n",
    "    'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login',\n",
    "    'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst',\n",
    "    'is_sm_ips_ports'\n",
    "]\n",
    "\n",
    "# SOC Analyst features used in causal discovery (from Step 2)\n",
    "CAUSAL_FEATURES = [\n",
    "    'proto', 'sttl', 'state', 'dtcpb', 'is_sm_ips_ports',\n",
    "    'dttl', 'stcpb', 'service', 'dwin', 'swin'\n",
    "]\n",
    "\n",
    "# Check files exist\n",
    "print(\"\\nVerifying required files:\")\n",
    "files_status = {}\n",
    "for name, file in [\n",
    "    ('LSTM Model', LSTM_MODEL),\n",
    "    ('Scaler', SCALER),\n",
    "    ('Causal Graph', CAUSAL_GRAPH),\n",
    "    ('Data', DATA_FILE)\n",
    "]:\n",
    "    exists = Path(file).exists()\n",
    "    status = \"‚úì\" if exists else \"‚úó\"\n",
    "    print(f\"  {status} {name}: {file}\")\n",
    "    files_status[name] = exists\n",
    "\n",
    "if not all(files_status.values()):\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Some files are missing!\")\n",
    "    print(\"Please ensure Steps 1-3 have been completed.\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: Load LSTM Model\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[2/8] Loading LSTM Model...\")\n",
    "\n",
    "# LSTM Architecture (must match Step 1)\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = LSTMClassifier(input_size=len(FEATURE_NAMES)).to(device)\n",
    "\n",
    "if files_status.get('LSTM Model'):\n",
    "    model.load_state_dict(torch.load(LSTM_MODEL, map_location=device))\n",
    "    model.eval()\n",
    "    print(\"‚úì Loaded LSTM model\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Using untrained model\")\n",
    "\n",
    "# Load scaler\n",
    "scaler = None\n",
    "if files_status.get('Scaler'):\n",
    "    scaler = joblib.load(SCALER)\n",
    "    print(f\"‚úì Loaded scaler ({scaler.n_features_in_} features)\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: Load Causal Graph\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[3/8] Loading Causal Graph...\")\n",
    "\n",
    "causal_graph = nx.DiGraph()\n",
    "if files_status.get('Causal Graph'):\n",
    "    causal_graph = pickle.load(open(CAUSAL_GRAPH, 'rb'))\n",
    "    print(f\"‚úì Loaded causal graph:\")\n",
    "    print(f\"  Nodes: {causal_graph.number_of_nodes()}\")\n",
    "    print(f\"  Edges: {causal_graph.number_of_edges()}\")\n",
    "    \n",
    "    # Show root causes\n",
    "    root_causes = [n for n in causal_graph.nodes() if causal_graph.in_degree(n) == 0]\n",
    "    if root_causes:\n",
    "        print(f\"  Root causes: {', '.join(root_causes[:5])}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Causal graph not found\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: Load and Preprocess Data\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[4/8] Loading Dataset...\")\n",
    "\n",
    "df = None\n",
    "if files_status.get('Data'):\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    print(f\"‚úì Loaded {len(df):,} records\")\n",
    "    \n",
    "    # Drop non-feature columns\n",
    "    drop_cols = ['id', 'attack_cat']\n",
    "    for col in drop_cols:\n",
    "        if col in df.columns:\n",
    "            df = df.drop(columns=[col])\n",
    "    \n",
    "    # Create Label column if needed\n",
    "    if 'label' in df.columns and 'Label' not in df.columns:\n",
    "        df['Label'] = df['label']\n",
    "    \n",
    "    # Encode categorical features\n",
    "    print(\"\\nEncoding categorical features...\")\n",
    "    categorical_cols = ['proto', 'service', 'state']\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            df[col] = df[col].fillna('unknown')\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "            print(f\"  ‚úì {col}: {df[col].nunique()} categories\")\n",
    "    \n",
    "    # Check label distribution\n",
    "    if 'Label' in df.columns:\n",
    "        print(f\"\\nLabel Distribution:\")\n",
    "        label_counts = df['Label'].value_counts()\n",
    "        for label, count in label_counts.items():\n",
    "            pct = count / len(df) * 100\n",
    "            label_name = \"Attack\" if label == 1 else \"Normal\"\n",
    "            print(f\"  {label_name} ({label}): {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Verify all features present\n",
    "    available_features = [f for f in FEATURE_NAMES if f in df.columns]\n",
    "    print(f\"\\n‚úì Available features: {len(available_features)}/{len(FEATURE_NAMES)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: Example Alert Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[5/8] Analyzing Example Alerts...\")\n",
    "\n",
    "if df is not None and len(df) > 0:\n",
    "    # Select diverse samples\n",
    "    print(\"\\nSelecting diverse alert samples...\")\n",
    "    \n",
    "    attack_samples = df[df['Label'] == 1].sample(n=min(3, len(df[df['Label'] == 1])), random_state=42)\n",
    "    normal_samples = df[df['Label'] == 0].sample(n=min(2, len(df[df['Label'] == 0])), random_state=42)\n",
    "    \n",
    "    print(f\"  ‚úì Selected {len(attack_samples)} attack + {len(normal_samples)} normal alerts\")\n",
    "    \n",
    "    # Example 1: First Attack Alert\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 1: Attack Alert Analysis\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    alert = attack_samples.iloc[0]\n",
    "    print(f\"\\nAlert ID: {alert.name}\")\n",
    "    print(f\"True Label: Attack\")\n",
    "    \n",
    "    # Show key features\n",
    "    key_features = ['proto', 'sttl', 'state', 'is_sm_ips_ports', 'spkts', 'dpkts']\n",
    "    print(\"\\nKey Feature Values:\")\n",
    "    for feat in key_features:\n",
    "        if feat in alert.index:\n",
    "            value = alert[feat]\n",
    "            print(f\"  {feat:20s}: {value}\")\n",
    "    \n",
    "    # Predict using LSTM\n",
    "    if scaler is not None:\n",
    "        alert_features = alert[FEATURE_NAMES].values.reshape(1, -1)\n",
    "        alert_scaled = scaler.transform(alert_features)\n",
    "        alert_tensor = torch.tensor(alert_scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(alert_tensor)\n",
    "            probs = torch.softmax(output, dim=1)[0]\n",
    "            pred_class = output.argmax(dim=1).item()\n",
    "            confidence = probs[pred_class].item()\n",
    "        \n",
    "        pred_label = \"Attack\" if pred_class == 1 else \"Normal\"\n",
    "        print(f\"\\nLSTM Prediction:\")\n",
    "        print(f\"  Predicted: {pred_label} (confidence: {confidence:.2%})\")\n",
    "        print(f\"  Normal prob: {probs[0]:.2%}\")\n",
    "        print(f\"  Attack prob: {probs[1]:.2%}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: Feature Importance (XAI)</\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[6/8] Computing Feature Importance...\")\n",
    "\n",
    "def compute_feature_importance_simple(model, alert_tensor, feature_names):\n",
    "    \"\"\"Simple gradient-based attribution\"\"\"\n",
    "    alert_tensor = alert_tensor.clone().requires_grad_(True)\n",
    "    \n",
    "    output = model(alert_tensor)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    \n",
    "    model.zero_grad()\n",
    "    output[0, pred_class].backward()\n",
    "    \n",
    "    gradients = alert_tensor.grad.squeeze().detach().cpu().numpy()\n",
    "    values = alert_tensor.squeeze().detach().cpu().numpy()\n",
    "    \n",
    "    # Attribution = gradient * input\n",
    "    attributions = gradients * values\n",
    "    \n",
    "    # Create feature importance dict\n",
    "    importance = []\n",
    "    for name, attr, val in zip(feature_names, attributions, values):\n",
    "        importance.append({\n",
    "            'feature': name,\n",
    "            'importance': float(attr),\n",
    "            'value': float(val),\n",
    "            'abs_importance': float(abs(attr))\n",
    "        })\n",
    "    \n",
    "    importance.sort(key=lambda x: x['abs_importance'], reverse=True)\n",
    "    return importance\n",
    "\n",
    "if df is not None and scaler is not None:\n",
    "    print(\"\\nTop 5 Important Features (Attack Alert):\")\n",
    "    importance = compute_feature_importance_simple(model, alert_tensor, FEATURE_NAMES)\n",
    "    \n",
    "    for i, feat in enumerate(importance[:5], 1):\n",
    "        print(f\"  {i}. {feat['feature']:20s} importance: {feat['importance']:+.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 7: Causal Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[7/8] Performing Causal Analysis...\")\n",
    "\n",
    "if causal_graph.number_of_nodes() > 0:\n",
    "    print(\"\\nCausal Relationships for Top Features:\")\n",
    "    \n",
    "    for feat_info in importance[:5]:\n",
    "        feat_name = feat_info['feature']\n",
    "        \n",
    "        if feat_name in causal_graph:\n",
    "            # Find ancestors (root causes)\n",
    "            ancestors = list(nx.ancestors(causal_graph, feat_name))\n",
    "            root_causes = [n for n in ancestors if causal_graph.in_degree(n) == 0]\n",
    "            \n",
    "            # Find direct causes\n",
    "            direct_causes = list(causal_graph.predecessors(feat_name))\n",
    "            \n",
    "            print(f\"\\n  {feat_name}:\")\n",
    "            if root_causes:\n",
    "                print(f\"    Root causes: {', '.join(root_causes)}\")\n",
    "            if direct_causes:\n",
    "                print(f\"    Direct causes: {', '.join(direct_causes)}\")\n",
    "            \n",
    "            # Find shortest path to label if it exists\n",
    "            if 'label' in causal_graph or 'Label' in causal_graph:\n",
    "                target = 'label' if 'label' in causal_graph else 'Label'\n",
    "                try:\n",
    "                    path = nx.shortest_path(causal_graph, feat_name, target)\n",
    "                    print(f\"    Path to outcome: {' ‚Üí '.join(path)}\")\n",
    "                except nx.NetworkXNoPath:\n",
    "                    print(f\"    No direct path to outcome\")\n",
    "        else:\n",
    "            print(f\"\\n  {feat_name}: Not in causal graph\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 8: Visualizations\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[8/8] Creating Visualizations...\")\n",
    "\n",
    "if df is not None and len(attack_samples) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Hybrid Explanation System Demo - UNSW-NB15', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Feature Importance\n",
    "    ax = axes[0, 0]\n",
    "    top_features = importance[:10]\n",
    "    features = [f['feature'] for f in top_features]\n",
    "    importances = [f['importance'] for f in top_features]\n",
    "    colors = ['red' if imp > 0 else 'blue' for imp in importances]\n",
    "    \n",
    "    ax.barh(features, importances, color=colors, alpha=0.7)\n",
    "    ax.set_xlabel('Importance Score')\n",
    "    ax.set_title('XAI: Feature Importance (Top 10)')\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Feature Value Distribution (Attack vs Normal)\n",
    "    ax = axes[0, 1]\n",
    "    if 'sttl' in df.columns:\n",
    "        attack_sttl = df[df['Label'] == 1]['sttl']\n",
    "        normal_sttl = df[df['Label'] == 0]['sttl']\n",
    "        \n",
    "        ax.hist(normal_sttl, bins=30, alpha=0.5, label='Normal', color='blue')\n",
    "        ax.hist(attack_sttl, bins=30, alpha=0.5, label='Attack', color='red')\n",
    "        ax.set_xlabel('sttl (Source TTL)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Distribution: sttl (Strong Attack Indicator)')\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Causal Graph (if available)\n",
    "    ax = axes[1, 0]\n",
    "    if causal_graph.number_of_nodes() > 0:\n",
    "        # Draw subset of causal graph\n",
    "        subgraph_nodes = list(causal_graph.nodes())[:15]  # Limit to 15 nodes\n",
    "        subgraph = causal_graph.subgraph(subgraph_nodes)\n",
    "        \n",
    "        pos = nx.spring_layout(subgraph, k=2, iterations=50, seed=42)\n",
    "        nx.draw_networkx_nodes(subgraph, pos, node_color='lightblue', \n",
    "                              node_size=800, alpha=0.9, ax=ax)\n",
    "        nx.draw_networkx_labels(subgraph, pos, font_size=7, ax=ax)\n",
    "        nx.draw_networkx_edges(subgraph, pos, edge_color='gray', \n",
    "                              arrows=True, arrowsize=15, ax=ax)\n",
    "        ax.set_title('Causal Graph (Subset)')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Causal graph\\nnot available', \n",
    "               ha='center', va='center', fontsize=12)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Plot 4: Prediction Confidence\n",
    "    ax = axes[1, 1]\n",
    "    if scaler is not None:\n",
    "        # Get predictions for multiple samples\n",
    "        sample_indices = list(range(min(100, len(df))))\n",
    "        predictions = []\n",
    "        \n",
    "        for idx in sample_indices:\n",
    "            sample = df.iloc[idx]\n",
    "            features = sample[FEATURE_NAMES].values.reshape(1, -1)\n",
    "            scaled = scaler.transform(features)\n",
    "            tensor = torch.tensor(scaled, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(tensor)\n",
    "                probs = torch.softmax(output, dim=1)[0]\n",
    "                predictions.append({\n",
    "                    'true': sample['Label'],\n",
    "                    'pred_prob': probs[1].item()\n",
    "                })\n",
    "        \n",
    "        pred_df = pd.DataFrame(predictions)\n",
    "        \n",
    "        # Plot confidence distributions\n",
    "        attack_conf = pred_df[pred_df['true'] == 1]['pred_prob']\n",
    "        normal_conf = pred_df[pred_df['true'] == 0]['pred_prob']\n",
    "        \n",
    "        ax.hist(normal_conf, bins=20, alpha=0.5, label='Normal', color='blue')\n",
    "        ax.hist(attack_conf, bins=20, alpha=0.5, label='Attack', color='red')\n",
    "        ax.set_xlabel('Attack Probability')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Model Confidence Distribution')\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('step4_demo_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n‚úì Saved visualization: step4_demo_visualization.png\")\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY: Step 4 Demo Complete\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ What We Demonstrated:\")\n",
    "print(\"  ‚Ä¢ LSTM-based alert classification (Step 1)\")\n",
    "print(\"  ‚Ä¢ Feature importance via gradient-based XAI\")\n",
    "print(\"  ‚Ä¢ Causal graph analysis (Step 2)\")\n",
    "print(\"  ‚Ä¢ Integration of XAI + Causal for hybrid explanations\")\n",
    "\n",
    "print(\"\\nüîç Key Findings:\")\n",
    "if df is not None:\n",
    "    print(f\"  ‚Ä¢ Dataset: {len(df):,} records\")\n",
    "    if 'Label' in df.columns:\n",
    "        attack_pct = (df['Label'] == 1).mean() * 100\n",
    "        print(f\"  ‚Ä¢ Attack rate: {attack_pct:.1f}%\")\n",
    "    \n",
    "    if 'sttl' in importance[0]['feature']:\n",
    "        print(f\"  ‚Ä¢ Top feature: {importance[0]['feature']} (TTL-based indicator)\")\n",
    "\n",
    "print(\"\\nüìä Generated Files:\")\n",
    "print(\"  ‚Ä¢ step4_demo_visualization.png - Comprehensive visualization\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"  ‚Ä¢ Run full Step 4 hybrid explainer for detailed explanations\")\n",
    "print(\"  ‚Ä¢ Proceed to Step 5 for quantitative evaluation\")\n",
    "print(\"  ‚Ä¢ Compare hybrid vs XAI-only approaches\")\n",
    "\n",
    "print(\"\\nüí° Key Advantages of Hybrid Approach:\")\n",
    "print(\"  ‚Ä¢ XAI tells us WHAT: Which features are important\")\n",
    "print(\"  ‚Ä¢ Causal tells us WHY/HOW: Root causes and causal chains\")\n",
    "print(\"  ‚Ä¢ Combined: Actionable recommendations for SOC analysts\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Demo Complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
